{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Day 2\n",
    "\n",
    "Our first Agentic Framework project!!\n",
    "\n",
    "Prepare yourself for something ridiculously easy.\n",
    "\n",
    "We're going to build a simple Agent system for generating cold sales outreach emails:\n",
    "1. Agent workflow\n",
    "2. Use of tools to call functions\n",
    "3. Agent collaboration via Tools and Handoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start - some setup:\n",
    "\n",
    "\n",
    "Please visit Sendgrid at: https://sendgrid.com/\n",
    "\n",
    "(Sendgrid is a Twilio company for sending emails.)\n",
    "\n",
    "Please set up an account - it's free! (at least, for me, right now).\n",
    "\n",
    "Once you've created an account, click on:\n",
    "\n",
    "Settings (left sidebar) >> API Keys >> Create API Key (button on top right)\n",
    "\n",
    "Copy the key to the clipboard, then add a new line to your .env file:\n",
    "\n",
    "`SENDGRID_API_KEY=xxxx`\n",
    "\n",
    "And also, within SendGrid, go to:\n",
    "\n",
    "Settings (left sidebar) >> Sender Authentication >> \"Verify a Single Sender\"  \n",
    "and verify that your own email address is a real email address, so that SendGrid can send emails for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, function_tool\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from typing import Dict\n",
    "import sendgrid\n",
    "import os\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "import asyncio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Agent workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions1 = \"You are a sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write professional, serious cold emails.\"\n",
    "\n",
    "instructions2 = \"You are a humorous, engaging sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\"\n",
    "\n",
    "instructions3 = \"You are a busy sales agent working for ComplAI, \\\n",
    "a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. \\\n",
    "You write concise, to the point cold emails.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent1 = Agent(\n",
    "        name=\"Professional Sales Agent\",\n",
    "        instructions=instructions1,\n",
    "        model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "sales_agent2 = Agent(\n",
    "        name=\"Engaging Sales Agent\",\n",
    "        instructions=instructions2,\n",
    "        model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "sales_agent3 = Agent(\n",
    "        name=\"Busy Sales Agent\",\n",
    "        instructions=instructions3,\n",
    "        model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Simplify Your SOC2 Compliance with ComplAI\n",
      "\n",
      "Dear [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well. My name is [Your Name], and I represent ComplAI, a cutting-edge SaaS tool designed to streamline SOC2 compliance and audit preparation through the power of AI.\n",
      "\n",
      "As organizations increasingly prioritize data security and trust, ensuring compliance can often be a complex and time-consuming process. ComplAI enables businesses to:\n",
      "\n",
      "- Automate documentation and evidence collection, significantly reducing the manual effort required.\n",
      "- Identify and address compliance gaps proactively, mitigating potential risks before audits.\n",
      "- Collaborate seamlessly across teams with real-time updates and insights.\n",
      "\n",
      "Our clients have reported a noticeable decrease in audit preparation time, along with improved accuracy and organization in their compliance efforts.\n",
      "\n",
      "I would appreciate the opportunity to discuss how ComplAI can help your organization simplify its compliance journey. Are you available for a brief call next week?\n",
      "\n",
      "Thank you for considering a tool that can elevate your SOC2 compliance strategy.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Job Title]  \n",
      "ComplAI  \n",
      "[Your Contact Information]  \n",
      "[Your Company Website]  "
     ]
    }
   ],
   "source": [
    "\n",
    "result = Runner.run_streamed(sales_agent1, input=\"Write a cold sales email\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Streamline Your SOC2 Compliance Process with AI\n",
      "\n",
      "Hi [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well. My name is [Your Name], and I‚Äôm reaching out from ComplAI, where we specialize in simplifying the SOC2 compliance journey for businesses like yours.\n",
      "\n",
      "As you know, maintaining SOC2 compliance can be a time-consuming and complex process, often pulling resources away from your core operations. Our AI-powered SaaS platform automates compliance tasks, enabling your team to focus on what truly matters‚Äîgrowing your business.\n",
      "\n",
      "Key benefits of our solution include:\n",
      "\n",
      "- **Automated Documentation**: Streamline the creation and maintenance of compliance documents.\n",
      "- **Real-Time Monitoring**: Keep track of compliance status with instant alerts and updates.\n",
      "- **Preparation for Audits**: Simplify the audit process with organized data and reports at your fingertips.\n",
      "\n",
      "We‚Äôve helped numerous organizations reduce compliance time by up to 50%, ensuring they stay ahead in an increasingly regulated landscape. \n",
      "\n",
      "Would you be open to a brief call next week to discuss how ComplAI can support your compliance efforts? I‚Äôm confident we can provide value to your organization.\n",
      "\n",
      "Looking forward to your response.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "ComplAI  \n",
      "[Your Phone Number]  \n",
      "[Your Email Address]  \n",
      "[Website URL]\n",
      "\n",
      "\n",
      "Subject: Let‚Äôs Make Compliance Less Painful Than a Papercut! üåü\n",
      "\n",
      "Hi [Recipient's Name],\n",
      "\n",
      "I hope this email finds you avoiding any compliance-related headaches today! ü§ï \n",
      "\n",
      "I‚Äôm reaching out from ComplAI, where we believe that preparing for SOC2 audits shouldn‚Äôt feel like a trip to the dentist‚Äîunpleasant, but unavoidable. With our AI-powered SaaS tool, we make navigating compliance as smooth as a buttered slide! \n",
      "\n",
      "Imagine an audit process where you spend more time sipping coffee and less time sifting through spreadsheets. Sounds dreamy, right? ‚òïüí≠ Our tool streamlines everything from documentation to readiness checks, reducing stress and saving you time (and potentially preventing spontaneous combustion). \n",
      "\n",
      "Curious to see how we can make compliance a walk in the park? Let‚Äôs set up a quick chat where I promise I won‚Äôt use any dentist analogies‚Ä¶ well, maybe just one! \n",
      "\n",
      "Looking forward to your reply!\n",
      "\n",
      "Best,  \n",
      "[Your Name]  \n",
      "[Your Position] at ComplAI  \n",
      "[Your Phone Number]  \n",
      "[Your Website URL]  \n",
      "\n",
      "P.S. If you respond with a fun compliance pun, I might just send you a virtual high five! üñêÔ∏è\n",
      "\n",
      "\n",
      "Subject: Simplify Your SOC2 Compliance with AI\n",
      "\n",
      "Hi [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well. I‚Äôm reaching out to introduce ComplAI, a powerful SaaS tool designed to streamline SOC2 compliance and audits using AI technology.\n",
      "\n",
      "With our solution, you can:\n",
      "- Automate compliance tasks\n",
      "- Track requirements in real-time\n",
      "- Prepare for audits with ease\n",
      "\n",
      "Let‚Äôs schedule a quick call to discuss how we can help your team ensure compliance and save valuable time.\n",
      "\n",
      "Best,  \n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "ComplAI  \n",
      "[Your Contact Information]  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = \"Write a cold sales email\"\n",
    "\n",
    "with trace(\"Parallel cold emails\"):\n",
    "    results = await asyncio.gather(\n",
    "        Runner.run(sales_agent1, message),\n",
    "        Runner.run(sales_agent2, message),\n",
    "        Runner.run(sales_agent3, message),\n",
    "    )\n",
    "\n",
    "outputs = [result.final_output for result in results]\n",
    "\n",
    "for output in outputs:\n",
    "    print(output + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_picker = Agent(\n",
    "    name=\"sales_picker\",\n",
    "    instructions=\"You pick the best cold sales email from the given options. \\\n",
    "Imagine you are a customer and pick the one you are most likely to respond to. \\\n",
    "Do not give an explanation; reply with the selected email only.\",\n",
    "    model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}. (request_id: req_89dcee85f7fcecb074dde31778046d0f)\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mWrite a cold sales email\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace(\u001b[33m\"\u001b[39m\u001b[33mSelection from sales people\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m      5\u001b[39m         Runner.run(sales_agent1, message),\n\u001b[32m      6\u001b[39m         Runner.run(sales_agent2, message),\n\u001b[32m      7\u001b[39m         Runner.run(sales_agent3, message),\n\u001b[32m      8\u001b[39m     )\n\u001b[32m      9\u001b[39m     outputs = [result.final_output \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m     11\u001b[39m     emails = \u001b[33m\"\u001b[39m\u001b[33mCold sales emails:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:218\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    213\u001b[39m logger.debug(\n\u001b[32m    214\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m )\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    219\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n\u001b[32m    220\u001b[39m             starting_agent,\n\u001b[32m    221\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    222\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    223\u001b[39m             copy.deepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[32m    224\u001b[39m             context_wrapper,\n\u001b[32m    225\u001b[39m         ),\n\u001b[32m    226\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    227\u001b[39m             agent=current_agent,\n\u001b[32m    228\u001b[39m             all_tools=all_tools,\n\u001b[32m    229\u001b[39m             original_input=original_input,\n\u001b[32m    230\u001b[39m             generated_items=generated_items,\n\u001b[32m    231\u001b[39m             hooks=hooks,\n\u001b[32m    232\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    233\u001b[39m             run_config=run_config,\n\u001b[32m    234\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    235\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    236\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    237\u001b[39m         ),\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    240\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    241\u001b[39m         agent=current_agent,\n\u001b[32m    242\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    251\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:762\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    760\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    763\u001b[39m     agent,\n\u001b[32m    764\u001b[39m     system_prompt,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    766\u001b[39m     output_schema,\n\u001b[32m    767\u001b[39m     all_tools,\n\u001b[32m    768\u001b[39m     handoffs,\n\u001b[32m    769\u001b[39m     context_wrapper,\n\u001b[32m    770\u001b[39m     run_config,\n\u001b[32m    771\u001b[39m     tool_use_tracker,\n\u001b[32m    772\u001b[39m     previous_response_id,\n\u001b[32m    773\u001b[39m )\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    776\u001b[39m     agent=agent,\n\u001b[32m    777\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    787\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:921\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    918\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m    919\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m    922\u001b[39m     system_instructions=system_prompt,\n\u001b[32m    923\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    924\u001b[39m     model_settings=model_settings,\n\u001b[32m    925\u001b[39m     tools=all_tools,\n\u001b[32m    926\u001b[39m     output_schema=output_schema,\n\u001b[32m    927\u001b[39m     handoffs=handoffs,\n\u001b[32m    928\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m    929\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    930\u001b[39m     ),\n\u001b[32m    931\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    932\u001b[39m )\n\u001b[32m    934\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:80\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     81\u001b[39m             system_instructions,\n\u001b[32m     82\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     83\u001b[39m             model_settings,\n\u001b[32m     84\u001b[39m             tools,\n\u001b[32m     85\u001b[39m             output_schema,\n\u001b[32m     86\u001b[39m             handoffs,\n\u001b[32m     87\u001b[39m             previous_response_id,\n\u001b[32m     88\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     89\u001b[39m         )\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m     92\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:248\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, stream)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    238\u001b[39m     logger.debug(\n\u001b[32m    239\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling LLM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with input:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson.dumps(list_input,\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrevious response id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprevious_response_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    249\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(previous_response_id),\n\u001b[32m    250\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(system_instructions),\n\u001b[32m    251\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    252\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    253\u001b[39m     include=converted_tools.includes,\n\u001b[32m    254\u001b[39m     tools=converted_tools.tools,\n\u001b[32m    255\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    256\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    257\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.truncation),\n\u001b[32m    258\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    259\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    260\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    261\u001b[39m     stream=stream,\n\u001b[32m    262\u001b[39m     extra_headers={**_HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    263\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    264\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    265\u001b[39m     text=response_format,\n\u001b[32m    266\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.store),\n\u001b[32m    267\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.reasoning),\n\u001b[32m    268\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    269\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py:1787\u001b[39m, in \u001b[36mAsyncResponses.create\u001b[39m\u001b[34m(self, input, model, background, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1756\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1757\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1758\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1785\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1786\u001b[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1788\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/responses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1789\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1790\u001b[39m             {\n\u001b[32m   1791\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1792\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1793\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbackground\u001b[39m\u001b[33m\"\u001b[39m: background,\n\u001b[32m   1794\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m: include,\n\u001b[32m   1795\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions,\n\u001b[32m   1796\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_output_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_output_tokens,\n\u001b[32m   1797\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1798\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1799\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprevious_response_id\u001b[39m\u001b[33m\"\u001b[39m: previous_response_id,\n\u001b[32m   1800\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: reasoning,\n\u001b[32m   1801\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1802\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1803\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1804\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1805\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   1806\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1807\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1808\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1809\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtruncation\u001b[39m\u001b[33m\"\u001b[39m: truncation,\n\u001b[32m   1810\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1811\u001b[39m             },\n\u001b[32m   1812\u001b[39m             response_create_params.ResponseCreateParamsStreaming\n\u001b[32m   1813\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   1814\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001b[32m   1815\u001b[39m         ),\n\u001b[32m   1816\u001b[39m         options=make_request_options(\n\u001b[32m   1817\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1818\u001b[39m         ),\n\u001b[32m   1819\u001b[39m         cast_to=Response,\n\u001b[32m   1820\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1821\u001b[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001b[32m   1822\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1742\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1729\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1730\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1737\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1738\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1739\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1740\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1741\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1549\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1546\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1548\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1549\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1553\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "message = \"Write a cold sales email\"\n",
    "\n",
    "with trace(\"Selection from sales people\"):\n",
    "    results = await asyncio.gather(\n",
    "        Runner.run(sales_agent1, message),\n",
    "        Runner.run(sales_agent2, message),\n",
    "        Runner.run(sales_agent3, message),\n",
    "    )\n",
    "    outputs = [result.final_output for result in results]\n",
    "\n",
    "    emails = \"Cold sales emails:\\n\\n\".join(outputs)\n",
    "\n",
    "    best = await Runner.run(sales_picker, emails)\n",
    "\n",
    "    print(f\"Best sales email:\\n{best.final_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go and check out the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: use of tools\n",
    "\n",
    "Now we will add a tool to the mix.\n",
    "\n",
    "Remember all that json boilerplate and the `handle_tool_calls()` function with the if logic.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent1 = Agent(\n",
    "        name=\"Professional Sales Agent\",\n",
    "        instructions=instructions1,\n",
    "        model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "sales_agent2 = Agent(\n",
    "        name=\"Engaging Sales Agent\",\n",
    "        instructions=instructions2,\n",
    "        model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "sales_agent3 = Agent(\n",
    "        name=\"Busy Sales Agent\",\n",
    "        instructions=instructions3,\n",
    "        model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent(name='Professional Sales Agent', instructions='You are a sales agent working for ComplAI, a company that provides a SaaS tool for ensuring SOC2 compliance and preparing for audits, powered by AI. You write professional, serious cold emails.', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_agent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 2 and 3: Tools and Agent interactions\n",
    "\n",
    "Remember all that boilerplate json?\n",
    "\n",
    "Simply wrap your function with the decorator `@function_tool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_email(body: str):\n",
    "    \"\"\" Send out an email with the given body to all sales prospects \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"manjunathasundi07@gmail.com\")  # Change to your verified sender\n",
    "    to_email = To(\"manjunathasundi07@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/plain\", body)\n",
    "    mail = Mail(from_email, to_email, \"Sales email\", content).get()\n",
    "    response = sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This has automatically been converted into a tool, with the boilerplate json created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTool(name='send_email', description='Send out an email with the given body to all sales prospects', params_json_schema={'properties': {'body': {'title': 'Body', 'type': 'string'}}, 'required': ['body'], 'title': 'send_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x121fead40>, strict_json_schema=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at it\n",
    "send_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And you can also convert an Agent into a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTool(name='sales_agent1', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent1_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123be9c60>, strict_json_schema=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool1 = sales_agent1.as_tool(tool_name=\"sales_agent1\", tool_description=\"Write a cold sales email\")\n",
    "tool1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So now we can gather all the tools together:\n",
    "\n",
    "A tool for each of our 3 email-writing agents\n",
    "\n",
    "And a tool for our function to send emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='sales_agent1', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent1_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1238cd260>, strict_json_schema=True),\n",
       " FunctionTool(name='send_email', description='Send out an email with the given body to all sales prospects', params_json_schema={'properties': {'body': {'title': 'Body', 'type': 'string'}}, 'required': ['body'], 'title': 'send_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x121fead40>, strict_json_schema=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"Write a cold sales email\"\n",
    "\n",
    "tool1 = sales_agent1.as_tool(tool_name=\"sales_agent1\", tool_description=description)\n",
    "# tool2 = sales_agent2.as_tool(tool_name=\"sales_agent2\", tool_description=description)\n",
    "# tool3 = sales_agent3.as_tool(tool_name=\"sales_agent3\", tool_description=description)\n",
    "\n",
    "tools = [tool1, send_email]\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now it's time for our Sales Manager - our planning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}. (request_id: req_da99cd41b5524c5780d01856891b1b32)\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mSend a cold sales email addressed to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mDear CEO\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace(\u001b[33m\"\u001b[39m\u001b[33mSales manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(sales_manager, message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:240\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    218\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    219\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n\u001b[32m    220\u001b[39m             starting_agent,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m         ),\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    241\u001b[39m         agent=current_agent,\n\u001b[32m    242\u001b[39m         all_tools=all_tools,\n\u001b[32m    243\u001b[39m         original_input=original_input,\n\u001b[32m    244\u001b[39m         generated_items=generated_items,\n\u001b[32m    245\u001b[39m         hooks=hooks,\n\u001b[32m    246\u001b[39m         context_wrapper=context_wrapper,\n\u001b[32m    247\u001b[39m         run_config=run_config,\n\u001b[32m    248\u001b[39m         should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    249\u001b[39m         tool_use_tracker=tool_use_tracker,\n\u001b[32m    250\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    251\u001b[39m     )\n\u001b[32m    252\u001b[39m should_run_agent_start_hooks = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    254\u001b[39m model_responses.append(turn_result.model_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:762\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    760\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    763\u001b[39m     agent,\n\u001b[32m    764\u001b[39m     system_prompt,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    766\u001b[39m     output_schema,\n\u001b[32m    767\u001b[39m     all_tools,\n\u001b[32m    768\u001b[39m     handoffs,\n\u001b[32m    769\u001b[39m     context_wrapper,\n\u001b[32m    770\u001b[39m     run_config,\n\u001b[32m    771\u001b[39m     tool_use_tracker,\n\u001b[32m    772\u001b[39m     previous_response_id,\n\u001b[32m    773\u001b[39m )\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    776\u001b[39m     agent=agent,\n\u001b[32m    777\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    787\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:921\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    918\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m    919\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m    922\u001b[39m     system_instructions=system_prompt,\n\u001b[32m    923\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    924\u001b[39m     model_settings=model_settings,\n\u001b[32m    925\u001b[39m     tools=all_tools,\n\u001b[32m    926\u001b[39m     output_schema=output_schema,\n\u001b[32m    927\u001b[39m     handoffs=handoffs,\n\u001b[32m    928\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m    929\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    930\u001b[39m     ),\n\u001b[32m    931\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    932\u001b[39m )\n\u001b[32m    934\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:80\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     81\u001b[39m             system_instructions,\n\u001b[32m     82\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     83\u001b[39m             model_settings,\n\u001b[32m     84\u001b[39m             tools,\n\u001b[32m     85\u001b[39m             output_schema,\n\u001b[32m     86\u001b[39m             handoffs,\n\u001b[32m     87\u001b[39m             previous_response_id,\n\u001b[32m     88\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     89\u001b[39m         )\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m     92\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:248\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, stream)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    238\u001b[39m     logger.debug(\n\u001b[32m    239\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling LLM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with input:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson.dumps(list_input,\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrevious response id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprevious_response_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    249\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(previous_response_id),\n\u001b[32m    250\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(system_instructions),\n\u001b[32m    251\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    252\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    253\u001b[39m     include=converted_tools.includes,\n\u001b[32m    254\u001b[39m     tools=converted_tools.tools,\n\u001b[32m    255\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    256\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    257\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.truncation),\n\u001b[32m    258\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    259\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    260\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    261\u001b[39m     stream=stream,\n\u001b[32m    262\u001b[39m     extra_headers={**_HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    263\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    264\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    265\u001b[39m     text=response_format,\n\u001b[32m    266\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.store),\n\u001b[32m    267\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.reasoning),\n\u001b[32m    268\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    269\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py:1787\u001b[39m, in \u001b[36mAsyncResponses.create\u001b[39m\u001b[34m(self, input, model, background, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1756\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1757\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1758\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1785\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1786\u001b[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1788\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/responses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1789\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1790\u001b[39m             {\n\u001b[32m   1791\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1792\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1793\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbackground\u001b[39m\u001b[33m\"\u001b[39m: background,\n\u001b[32m   1794\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m: include,\n\u001b[32m   1795\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions,\n\u001b[32m   1796\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_output_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_output_tokens,\n\u001b[32m   1797\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1798\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1799\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprevious_response_id\u001b[39m\u001b[33m\"\u001b[39m: previous_response_id,\n\u001b[32m   1800\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: reasoning,\n\u001b[32m   1801\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1802\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1803\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1804\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1805\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   1806\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1807\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1808\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1809\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtruncation\u001b[39m\u001b[33m\"\u001b[39m: truncation,\n\u001b[32m   1810\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1811\u001b[39m             },\n\u001b[32m   1812\u001b[39m             response_create_params.ResponseCreateParamsStreaming\n\u001b[32m   1813\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   1814\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001b[32m   1815\u001b[39m         ),\n\u001b[32m   1816\u001b[39m         options=make_request_options(\n\u001b[32m   1817\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1818\u001b[39m         ),\n\u001b[32m   1819\u001b[39m         cast_to=Response,\n\u001b[32m   1820\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1821\u001b[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001b[32m   1822\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1742\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1729\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1730\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1737\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1738\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1739\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1740\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1741\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1549\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1546\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1548\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1549\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1553\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "instructions =\"You are a sales manager working for ComplAI. You use the tools given to you to generate cold sales emails. \\\n",
    "You never generate sales emails yourself; you always use the tools. \\\n",
    "You try all 3 sales_agent tools once before choosing the best one. \\\n",
    "You pick the single best email and use the send_email tool to send the best email (and only the best email) to the user.\"\n",
    "\n",
    "\n",
    "sales_manager = Agent(name=\"Sales Manager\", instructions=instructions, tools=tools, model=\"gpt-4o-mini\")\n",
    "\n",
    "message = \"Send a cold sales email addressed to 'Dear CEO'\"\n",
    "\n",
    "with trace(\"Sales manager\"):\n",
    "    result = await Runner.run(sales_manager, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Wait - you didn't get an email??</h2>\n",
    "            <span style=\"color:#ff7800;\">With much thanks to student Chris S. for describing his issue and fixes. \n",
    "            If you don't receive an email after running the prior cell, here are some things to check: <br/>\n",
    "            First, check your Spam folder! Several students have missed that the emails arrived in Spam!<br/>Second, print(result) and see if you are receiving errors about SSL. \n",
    "            If you're receiving SSL errors, then please check out theses <a href=\"https://chatgpt.com/share/680620ec-3b30-8012-8c26-ca86693d0e3d\">networking tips</a> and see the note in the next cell. Also look at the trace in OpenAI, and investigate on the SendGrid website, to hunt for clues. Let me know if I can help!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And one more suggestion to send emails from student Oleksandr on Windows 11:\n",
    "\n",
    "If you are getting certificate SSL errors, then:  \n",
    "Run this in a terminal: `uv pip install --upgrade certifi`\n",
    "\n",
    "Then run this code:\n",
    "```python\n",
    "import certifi\n",
    "import os\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "```\n",
    "\n",
    "Thank you Oleksandr!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember to check the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "And then check your email!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handoffs represent a way an agent can delegate to an agent, passing control to it\n",
    "\n",
    "Handoffs and Agents-as-tools are similar:\n",
    "\n",
    "In both cases, an Agent can collaborate with another Agent\n",
    "\n",
    "With tools, control passes back\n",
    "\n",
    "With handoffs, control passes across\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_instructions = \"You can write a subject for a cold sales email. \\\n",
    "You are given a message and you need to write a subject for an email that is likely to get a response.\"\n",
    "\n",
    "html_instructions = \"You can convert a text email body to an HTML email body. \\\n",
    "You are given a text email body which might have some markdown \\\n",
    "and you need to convert it to an HTML email body with simple, clear, compelling layout and design.\"\n",
    "\n",
    "subject_writer = Agent(name=\"Email subject writer\", instructions=subject_instructions, model=\"gpt-4o-mini\")\n",
    "subject_tool = subject_writer.as_tool(tool_name=\"subject_writer\", tool_description=\"Write a subject for a cold sales email\")\n",
    "\n",
    "html_converter = Agent(name=\"HTML email body converter\", instructions=html_instructions, model=\"gpt-4o-mini\")\n",
    "html_tool = html_converter.as_tool(tool_name=\"html_converter\",tool_description=\"Convert a text email body to an HTML email body\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_html_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "    \"\"\" Send out an email with the given subject and HTML body to all sales prospects \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"ed@edwarddonner.com\")  # Change to your verified sender\n",
    "    to_email = To(\"ed.donner@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/html\", html_body)\n",
    "    mail = Mail(from_email, to_email, subject, content).get()\n",
    "    response = sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [subject_tool, html_tool, send_html_email]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='subject_writer', description='Write a subject for a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'subject_writer_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123ca9120>, strict_json_schema=True),\n",
       " FunctionTool(name='html_converter', description='Convert a text email body to an HTML email body', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'html_converter_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123ca9e40>, strict_json_schema=True),\n",
       " FunctionTool(name='send_html_email', description='Send out an email with the given subject and HTML body to all sales prospects', params_json_schema={'properties': {'subject': {'title': 'Subject', 'type': 'string'}, 'html_body': {'title': 'Html Body', 'type': 'string'}}, 'required': ['subject', 'html_body'], 'title': 'send_html_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123ca9440>, strict_json_schema=True)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions =\"You are an email formatter and sender. You receive the body of an email to be sent. \\\n",
    "You first use the subject_writer tool to write a subject for the email, then use the html_converter tool to convert the body to HTML. \\\n",
    "Finally, you use the send_html_email tool to send the email with the subject and HTML body.\"\n",
    "\n",
    "\n",
    "emailer_agent = Agent(\n",
    "    name=\"Email Manager\",\n",
    "    instructions=instructions,\n",
    "    tools=tools,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    handoff_description=\"Convert an email to HTML and send it\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have 3 tools and 1 handoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionTool(name='sales_agent1', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent1_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1238cd260>, strict_json_schema=True), FunctionTool(name='sales_agent2', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent2_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123beb060>, strict_json_schema=True), FunctionTool(name='sales_agent3', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent3_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123bebf60>, strict_json_schema=True)]\n",
      "[Agent(name='Email Manager', instructions='You are an email formatter and sender. You receive the body of an email to be sent. You first use the subject_writer tool to write a subject for the email, then use the html_converter tool to convert the body to HTML. Finally, you use the send_html_email tool to send the email with the subject and HTML body.', handoff_description='Convert an email to HTML and send it', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='subject_writer', description='Write a subject for a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'subject_writer_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123ca9120>, strict_json_schema=True), FunctionTool(name='html_converter', description='Convert a text email body to an HTML email body', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'html_converter_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123ca9e40>, strict_json_schema=True), FunctionTool(name='send_html_email', description='Send out an email with the given subject and HTML body to all sales prospects', params_json_schema={'properties': {'subject': {'title': 'Subject', 'type': 'string'}, 'html_body': {'title': 'Html Body', 'type': 'string'}}, 'required': ['subject', 'html_body'], 'title': 'send_html_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x123ca9440>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)]\n"
     ]
    }
   ],
   "source": [
    "tools = [tool1, tool2, tool3]\n",
    "handoffs = [emailer_agent]\n",
    "print(tools)\n",
    "print(handoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}. (request_id: req_bb5e18b196ff84176024a3fdac7ea717)\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mSend out a cold sales email addressed to Dear CEO from Alice\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace(\u001b[33m\"\u001b[39m\u001b[33mAutomated SDR\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(sales_manager, message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:240\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    218\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    219\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n\u001b[32m    220\u001b[39m             starting_agent,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m         ),\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    241\u001b[39m         agent=current_agent,\n\u001b[32m    242\u001b[39m         all_tools=all_tools,\n\u001b[32m    243\u001b[39m         original_input=original_input,\n\u001b[32m    244\u001b[39m         generated_items=generated_items,\n\u001b[32m    245\u001b[39m         hooks=hooks,\n\u001b[32m    246\u001b[39m         context_wrapper=context_wrapper,\n\u001b[32m    247\u001b[39m         run_config=run_config,\n\u001b[32m    248\u001b[39m         should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    249\u001b[39m         tool_use_tracker=tool_use_tracker,\n\u001b[32m    250\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    251\u001b[39m     )\n\u001b[32m    252\u001b[39m should_run_agent_start_hooks = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    254\u001b[39m model_responses.append(turn_result.model_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:762\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    760\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    763\u001b[39m     agent,\n\u001b[32m    764\u001b[39m     system_prompt,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    766\u001b[39m     output_schema,\n\u001b[32m    767\u001b[39m     all_tools,\n\u001b[32m    768\u001b[39m     handoffs,\n\u001b[32m    769\u001b[39m     context_wrapper,\n\u001b[32m    770\u001b[39m     run_config,\n\u001b[32m    771\u001b[39m     tool_use_tracker,\n\u001b[32m    772\u001b[39m     previous_response_id,\n\u001b[32m    773\u001b[39m )\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    776\u001b[39m     agent=agent,\n\u001b[32m    777\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    787\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/run.py:921\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    918\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m    919\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m    922\u001b[39m     system_instructions=system_prompt,\n\u001b[32m    923\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    924\u001b[39m     model_settings=model_settings,\n\u001b[32m    925\u001b[39m     tools=all_tools,\n\u001b[32m    926\u001b[39m     output_schema=output_schema,\n\u001b[32m    927\u001b[39m     handoffs=handoffs,\n\u001b[32m    928\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m    929\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    930\u001b[39m     ),\n\u001b[32m    931\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    932\u001b[39m )\n\u001b[32m    934\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:80\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     81\u001b[39m             system_instructions,\n\u001b[32m     82\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     83\u001b[39m             model_settings,\n\u001b[32m     84\u001b[39m             tools,\n\u001b[32m     85\u001b[39m             output_schema,\n\u001b[32m     86\u001b[39m             handoffs,\n\u001b[32m     87\u001b[39m             previous_response_id,\n\u001b[32m     88\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     89\u001b[39m         )\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m     92\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:248\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, stream)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    238\u001b[39m     logger.debug(\n\u001b[32m    239\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling LLM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with input:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson.dumps(list_input,\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrevious response id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprevious_response_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    249\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(previous_response_id),\n\u001b[32m    250\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(system_instructions),\n\u001b[32m    251\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    252\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    253\u001b[39m     include=converted_tools.includes,\n\u001b[32m    254\u001b[39m     tools=converted_tools.tools,\n\u001b[32m    255\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    256\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    257\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.truncation),\n\u001b[32m    258\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    259\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    260\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    261\u001b[39m     stream=stream,\n\u001b[32m    262\u001b[39m     extra_headers={**_HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    263\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    264\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    265\u001b[39m     text=response_format,\n\u001b[32m    266\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.store),\n\u001b[32m    267\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.reasoning),\n\u001b[32m    268\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    269\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py:1787\u001b[39m, in \u001b[36mAsyncResponses.create\u001b[39m\u001b[34m(self, input, model, background, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1756\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1757\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1758\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1785\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1786\u001b[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1788\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/responses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1789\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1790\u001b[39m             {\n\u001b[32m   1791\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1792\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1793\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbackground\u001b[39m\u001b[33m\"\u001b[39m: background,\n\u001b[32m   1794\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m: include,\n\u001b[32m   1795\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions,\n\u001b[32m   1796\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_output_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_output_tokens,\n\u001b[32m   1797\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1798\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1799\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprevious_response_id\u001b[39m\u001b[33m\"\u001b[39m: previous_response_id,\n\u001b[32m   1800\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: reasoning,\n\u001b[32m   1801\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1802\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1803\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1804\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1805\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   1806\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1807\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1808\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1809\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtruncation\u001b[39m\u001b[33m\"\u001b[39m: truncation,\n\u001b[32m   1810\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1811\u001b[39m             },\n\u001b[32m   1812\u001b[39m             response_create_params.ResponseCreateParamsStreaming\n\u001b[32m   1813\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   1814\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001b[32m   1815\u001b[39m         ),\n\u001b[32m   1816\u001b[39m         options=make_request_options(\n\u001b[32m   1817\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1818\u001b[39m         ),\n\u001b[32m   1819\u001b[39m         cast_to=Response,\n\u001b[32m   1820\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1821\u001b[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001b[32m   1822\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1742\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1729\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1730\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1737\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1738\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1739\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1740\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1741\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Manju/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1549\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1546\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1548\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1549\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1553\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-wSEgEBneBB5H0oiuHpktBa5B on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "sales_manager_instructions = \"You are a sales manager working for ComplAI. You use the tools given to you to generate cold sales emails. \\\n",
    "You never generate sales emails yourself; you always use the tools. \\\n",
    "You try all 3 sales agent tools at least once before choosing the best one. \\\n",
    "You can use the tools multiple times if you're not satisfied with the results from the first try. \\\n",
    "You select the single best email using your own judgement of which email will be most effective. \\\n",
    "After picking the email, you handoff to the Email Manager agent to format and send the email.\"\n",
    "\n",
    "\n",
    "sales_manager = Agent(\n",
    "    name=\"Sales Manager\",\n",
    "    instructions=sales_manager_instructions,\n",
    "    tools=tools,\n",
    "    handoffs=handoffs,\n",
    "    model=\"gpt-4o-mini\")\n",
    "\n",
    "message = \"Send out a cold sales email addressed to Dear CEO from Alice\"\n",
    "\n",
    "with trace(\"Automated SDR\"):\n",
    "    result = await Runner.run(sales_manager, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to check the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "And then check your email!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Can you identify the Agentic design patterns that were used here?<br/>\n",
    "            What is the 1 line that changed this from being an Agentic \"workflow\" to \"agent\" under Anthropic's definition?<br/>\n",
    "            Try adding in more tools and Agents! You could have tools that handle the mail merge to send to a list.<br/><br/>\n",
    "            HARD CHALLENGE: research how you can have SendGrid call a Callback webhook when a user replies to an email,\n",
    "            Then have the SDR respond to keep the conversation going! This may require some \"vibe coding\" üòÇ\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">This is immediately applicable to Sales Automation; but more generally this could be applied to  end-to-end automation of any business process through conversations and tools. Think of ways you could apply an Agent solution\n",
    "            like this in your day job.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra note:\n",
    "\n",
    "Google has announced their Agent Development Kit (ADK) which is in early preview. It's still under development, so it's too early for us to cover it here. But it's interesting to note that it looks quite similar to OpenAI Agents SDK. To give you a preview, here's a peak at sample code from ADK:\n",
    "\n",
    "```\n",
    "root_agent = Agent(\n",
    "    name=\"weather_time_agent\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"Agent to answer questions about the time and weather in a city.\",\n",
    "    instruction=\"You are a helpful agent who can answer user questions about the time and weather in a city.\",\n",
    "    tools=[get_weather, get_current_time]\n",
    ")\n",
    "```\n",
    "\n",
    "Well, that looks familiar!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
